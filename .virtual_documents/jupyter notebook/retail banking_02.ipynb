





import pandas as pd                   # for data processing
import numpy as np                    # for data processing
import matplotlib.pyplot as plt       # for visualizations 
import seaborn as sns                 # for visualizations 
from datetime import datetime         # for working with date and time objects
import datetime as dt                 # for working with date and time objects
import warnings
warnings.filterwarnings('ignore')     # for preventing unwanted warning message


df = pd.read_csv(r'../raw_data/bank_data_C.csv')


df.head()





df.isna().sum()


df.shape


df.dtypes





df['CustomerDOB'] = pd.to_datetime(df['CustomerDOB'], errors='coerce')
df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], errors='coerce')


df.dtypes





df['TransactionDate'].nunique()


df['TransactionDate'].unique()











def cal_customer_age(age):
    df['CustomerAge'] = df['TransactionDate'].dt.year - df['CustomerDOB'].dt.year
    return df


df = cal_customer_age(df)


df.head()





df[df['CustomerAge'] < 0]['CustomerDOB'].nunique()   # to show the total number of records with negative values


def correct_Age(date):
    if date.year > 2016:
        date = date.replace(year = date.year - 100)
    return date


df['CustomerDOB'] = df['CustomerDOB'].apply(correct_Age)


df[df['CustomerAge'] < 0]['CustomerDOB'].nunique()   # to verify the effectiveness of the "correct_Age" function


df = cal_customer_age(df)   # re-calculating the customer's age again


df[df['CustomerAge'] < 0]['CustomerDOB'].nunique()   # to verify the effectiveness of the "correct_Age" function


df.head()





plt.figure(figsize=(15,3))
sns.histplot(df['CustomerAge'], kde=False, bins=10, color='teal')
plt.title('Customer Age Gistribution', weight='bold')
plt.xlabel('Age Distribution', weight='bold')
plt.ylabel('Frequency', weight='bold')
plt.show()





df[df['CustomerAge'] > 100 ]['CustomerDOB'].value_counts()





avg_age = df.loc[df['CustomerAge'] <= 100]['CustomerAge'].mean()
avg_age


df.loc[df['CustomerAge'] > 100, 'CustomerAge'] = avg_age





df[df['CustomerAge'] > 100 ]['CustomerDOB']


plt.figure(figsize=(15,3))
sns.histplot(df['CustomerAge'], kde=False, bins=10, color='teal')
plt.title('Customer Age Gistribution', weight='bold')
plt.xlabel('Age Distribution', weight='bold')
plt.ylabel('Frequency', weight='bold')
plt.show()








def correctCustGender(x):
    if x == 'M':
        return x
    elif x == 'F':
        return x
    else:
        return 'M'


df['CustGender'] = df['CustGender'].apply(correctCustGender)


print(df['CustGender'].unique())


df.head(2)





df['TransactionAmount (INR)'].sort_values(ascending=True)


df[df['TransactionAmount (INR)'] == 0].value_counts().sum()


df.drop(df[df['TransactionAmount (INR)'] == 0].index, axis=0, inplace=True)  # dropping the records/rows with irrelevant transaction amount


df[df['TransactionAmount (INR)'] == 0].value_counts().sum()


df.shape


df.head()


df.to_csv("C:/Users/user/Desktop/retail banking/processed_data/processed_data_v1.2.csv", index=False)








last_transaction_day = df['TransactionDate'].max()
last_transaction_day


rfm_table = df.groupby('CustomerID').agg({
    'TransactionDate': lambda x: (last_transaction_day - x.max()).days+1,
    'TransactionID': 'count',
    'TransactionAmount (INR)': 'sum'
})





rfm_table.rename(columns = {
    'TransactionDate': 'Recency',
    'TransactionID': 'Frequency',
    'TransactionAmount (INR)': 'Monetary'
}, inplace=True)


rfm_table.head()


rfm_table['Frequency'].nunique()





plt.figure(figsize=(20,4))
plt.subplot(1,2, 1)
sns.histplot(rfm_table['Recency'], bins=10, color='Teal', edgecolor='black')
plt.title(f'Histogram for: {'Recency'} Distribution', weight='bold')
plt.xlabel('Recency values', weight='bold')
plt.ylabel('Count', weight='bold')

plt.subplot(1, 2, 2)
sns.histplot(rfm_table['Frequency'], bins=10, color='Teal', edgecolor='black')
plt.title(f'Histogram for: {'Frequency'} Distribution', weight='bold')
plt.xlabel('Frequency values', weight='bold')
plt.ylabel('Count', weight='bold')

plt.tight_layout()
plt.show();


plt.figure(figsize=(20,4))
sns.histplot(rfm_table['Monetary'], bins=np.logspace(0,2,20), color='Teal', edgecolor="Black")
plt.xscale('log')
plt.yscale('log')
plt.title(f'Histogram for: {'Frequency'} Distribution', weight='bold')
plt.xlabel('Monetary value', weight='bold')
plt.ylabel('Count', weight='bold')

plt.show();





rfm_table['R'] = pd.qcut(rfm_table['Recency'].rank(method='first'), q=5, labels= range(5,0,-1))
rfm_table['F'] = pd.qcut(rfm_table['Frequency'].rank(method='first'), q=5, labels= range(1,6))
rfm_table['M'] = pd.qcut(rfm_table['Monetary'].rank(method='first'), q=5, labels= range(1,6))


rfm_table.head()


rfm_table['RFM_Group'] = rfm_table['R'].astype(str) + rfm_table['F'].astype(str) + rfm_table['M'].astype(str)


rfm_table.head(3)


rfm_table['RFM_Score'] = rfm_table[['R', 'F', 'M']].sum(axis=1)


rfm_table.head(3)








rfm_table['RFM_Score'].min()


rfm_table['RFM_Score'].max()


def segment_customers(RFM_Score):
    if RFM_Score >= 13:
        return 'Champions'
    elif RFM_Score >= 10:
        return 'Loyal Customers'
    elif RFM_Score >= 8:
        return 'Potential Loyalists'
    elif RFM_Score >= 6:
        return 'New Customers'
    elif RFM_Score == 5:
        return 'Customers Needing Attention'
    elif RFM_Score >= 3:
        return 'At Risk'
    else:
        return 'Lost'


rfm_table['RFM_Segment'] = rfm_table['RFM_Score'].apply(segment_customers)


rfm_table.head()





plt.figure(figsize=(20,4))
sns.countplot(x=rfm_table['RFM_Score'], palette='Paired')
plt.title('RFM Score Distributions', weight='bold')
plt.xlabel('RFM Score', weight='bold')
plt.ylabel('Frequency', weight='bold')
plt.show();








rfm_table['R'] = rfm_table['R'].astype(int)
rfm_table['F'] = rfm_table['F'].astype(int)
rfm_table['M'] = rfm_table['M'].astype(int)
rfm_table['Weighted_Score'] = (rfm_table['R'] * 0.15) + (rfm_table['F'] * 0.28) + (rfm_table['M'] * 0.57).round(2)


rfm_table.head()


rfm_table['Weighted_Score'].max()


rfm_table['Weighted_Score'].min()





# Here, I write a function to segment the Weighted Score
def weight_segment(Weighted_Score):
    if Weighted_Score > 4:
        return 'Extremely High'
    elif Weighted_Score >= 3:
        return 'High'
    elif Weighted_Score > 2:
        return 'Medium'
    else:
        return 'Low'


rfm_table['Weighted_Segment'] = rfm_table['Weighted_Score'].apply(weight_segment)


rfm_table.head()


# Here is the visualisation of the Weighted Segment
plt.figure(figsize=(20,4))
sns.countplot(x=rfm_table['Weighted_Segment'], palette='cubehelix', width=0.5)
plt.title('Weighted Segment Distribution', weight='bold')
plt.xlabel('Weighted Segment', weight='bold')
plt.ylabel('Frequency', weight='bold')
plt.show();


df.to_csv("C:/Users/user/Desktop/retail banking/rfm_data/rfm_data_v1.0.csv", index=False)


customer_segment = rfm_table['RFM_Segment'].value_counts().reset_index()
customer_segment.head()








plt.figure(figsize=(20,5))
sns.barplot(x='RFM_Segment', y='count', data=customer_segment, color='Teal', palette='cool')
plt.title('The distribution of Customer Segments', weight='bold')
plt.xlabel('Customer Segments', weight='bold')
plt.ylabel('Count', weight='bold')
plt.show();








from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import yellowbrick
from yellowbrick.cluster import KElbowVisualizer


rfm_table.head(3)


clustering_data = rfm_table.copy()


clustering_data.head(3)


clustering_data.drop(columns=['RFM_Group', 'RFM_Segment', 'Weighted_Score', 'Weighted_Segment'], axis=1, inplace=True)


clustering_data.head(3)





scaler = StandardScaler()


scalled_data = scaler.fit_transform(clustering_data)


scalled_data


model = KMeans(random_state=42)





plot_model = KElbowVisualizer(model, k = range(2,10), metric= 'distortion', timings=False)
plot_model.fit(scalled_data)


plot_model_02 = KElbowVisualizer(model, k = (2,10), metric= 'calinski_harabasz', timings=False)
plot_model_02.fit(scalled_data)








pca = PCA(n_components=2)
scalled_data_pca = pca.fit_transform(scalled_data)

for k in [2, 4]:
    model = KMeans(n_clusters=k, random_state=42)
    labels = model.fit_predict(scalled_data)
    
    plt.figure(figsize=(15,7))
    plt.scatter(scalled_data_pca[:,0], scalled_data_pca[:,1], c=labels, cmap='viridis')
    plt.title(f'K-Means Clusters (k={k})')
    plt.show()



optimal_k = 4


final_model = KMeans(n_clusters=optimal_k, random_state=42)
final_model.fit(scalled_data)


final_model.labels_


clustering_data['Cluster'] = final_model.labels_


clustering_data.head()


clustering_data.groupby('Cluster')[['Recency', 'Frequency', 'Monetary', 'RFM_Score']].mean().reset_index()


clustering_data.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean().reset_index()


plt.figure(figsize=(15,5))
plt.subplot(1,2,1)  # RFM Distribution by Cluster
sns.boxplot(data=clustering_data, x='Cluster', y='RFM_Score', palette='viridis')
plt.title('RFM Score Distribution Across Clusters', weight='bold')
plt.xlabel('Customer Cluster', weight='bold')
plt.ylabel('RFM Score',weight='bold')


plt.subplot(1,2,2) # Monetary vs Frequency Scatter Plot
sns.scatterplot(data=clustering_data, x='Frequency', y='Monetary', hue='Cluster', palette='Set2', s=100)
plt.title('Customer Clusters Based on Frequency and Monetary Value', weight='bold')
plt.xlabel('Purchase Frequency', weight='bold')
plt.ylabel('Total Monetary Value', weight='bold')
plt.tight_layout()
plt.show();


plt.figure(figsize=(15,5))
plt.subplot(1,2,1)  # Average RFM Components per Cluster
# clustering_data.plot(x='Cluster', kind='bar')
# plt.title('Average Recency, Frequency, and Monetary Value by Cluster',  weight='bold')
# plt.ylabel('Average Values',  weight='bold')

# plt.subplot(1,2,2)  # Cluster Size Distribution
clustering_data['Cluster'].value_counts().sort_index().plot(kind='bar', color='cornflowerblue')
plt.title('Number of Customers in Each Cluster', weight='bold')
plt.xlabel('Cluster',  weight='bold')
plt.ylabel('Customer Count',  weight='bold')
plt.show();









